{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysing Coastal Change with Landsat\n",
    "\n",
    "This notebook is a simplified, worked example of analysing multiple years of\n",
    "Landsat data to locate the coastline, and its change over time.\n",
    "\n",
    "The original implementation of this algorithm was achieved by Geoscience Australia\n",
    "and is available at [dea-costlines](https://github.com/geoscienceAustralia/dea-coastlines).\n",
    "There is a new version, which is more generic available at\n",
    "[coastlines](https://github.com/auspatious/coastlines).\n",
    "\n",
    "## Requirements\n",
    "\n",
    "The algorithm uses two fundameltal datasets, first, optical Earth observation data,\n",
    "and Landsat is ideal, as it goes back over forty years. And second, is a tidal\n",
    "model, which is used to annotate scenes with a tide height, and to filter\n",
    "those scenes to just those in the middle of the tide range, therefore establishing\n",
    "an 'average' coastline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration and setup\n",
    "\n",
    "First, we import libraries and tools that we need to run the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pystac_client import Client\n",
    "from odc.stac import load, configure_s3_access\n",
    "\n",
    "from dask.distributed import Client as DaskClient\n",
    "\n",
    "from dea_tools.coastal import pixel_tides\n",
    "from dea_tools.spatial import points_on_line\n",
    "from coastlines.utils import tide_cutoffs, extract_contours\n",
    "from coastlines.vector import annual_movements, calculate_regressions\n",
    "from ipyleaflet import basemaps\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up our environment\n",
    "\n",
    "We're going to access Landsat data from USGS using the Element-84 STAC API.\n",
    "\n",
    "The `configure_s3_access` function will set up the environment for the requester\n",
    "pays bucket on S3, which USGS shares data from. And we use Dask to lazy-load\n",
    "data and run the computation in parallel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STAC Catalog URL\n",
    "catalog = \"https://earth-search.aws.element84.com/v1\"\n",
    "\n",
    "# Create a STAC Client\n",
    "client = Client.open(catalog)\n",
    "\n",
    "# Tide data and config\n",
    "home = Path(\"~\")\n",
    "tide_data_location = f\"{home}/tide_models\"\n",
    "\n",
    "# This line will fail if you don't have credentials configured\n",
    "_ = configure_s3_access(cloud_defaults=True, requester_pays=True)\n",
    "\n",
    "# Set up a dask client\n",
    "dask_client = DaskClient(n_workers=4, threads_per_worker=8)\n",
    "dask_client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up a study location\n",
    "\n",
    "Configure a spatial location and a time range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find a location you're interested in on Google Maps and copy the coordinates\n",
    "# by right-clicking on the map and clicking the coordinates\n",
    "\n",
    "# These coords are in the order Y then X, or Latitude then Longitude\n",
    "coords = 12.293, 109.225  # Near Phuong Vinh Hoa \n",
    "buffer = 0.05\n",
    "bbox = (coords[1] - buffer, coords[0] - buffer, coords[1] + buffer, coords[0] + buffer)\n",
    "landsat_stretch = dict(vmin=7500, vmax=18000)\n",
    "\n",
    "datetime = \"2019/2024\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find and load data\n",
    "\n",
    "Search for Landsat scenes from the STAC API.\n",
    "\n",
    "Then lazy-load data using `odc-stac`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = client.search(\n",
    "    collections=[\"landsat-c2-l2\"],\n",
    "    bbox=bbox,\n",
    "    datetime=datetime,\n",
    ").item_collection()\n",
    "\n",
    "print(f\"Found {len(items)} items\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load(\n",
    "    items,\n",
    "    bbox=bbox,\n",
    "    collection=\"landsat-c2-l2\",\n",
    "    measurements=[\"red\", \"green\", \"blue\", \"nir08\", \"swir16\", \"qa_pixel\"],\n",
    "    groupby=\"solar_day\",\n",
    "    chunks={\"x\": 2048, \"y\": 2048},\n",
    ")\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preview data\n",
    "\n",
    "This cell first selects the first four scenes using the `isel` or \"index select\" function.\n",
    "And then plots that from an array, so that we get an RGB visualisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = data[[\"red\", \"green\", \"blue\"]].isel(time=range(0, 4))\n",
    "subset.to_array().plot.imshow(col=\"time\", col_wrap=2, size=6, **landsat_stretch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data processing\n",
    "\n",
    "Now we know we have some good data, we can start processing. First we need to mask\n",
    "out clouds, so that they don't impact our results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bit flag mask for the QA_PIXEL band\n",
    "# We need bits 3 and 4, which are the 4th and 5th bits from the right (0-indexed)\n",
    "bitflags = 0b00011000\n",
    "cloud_mask = (data.qa_pixel & bitflags) != 0\n",
    "\n",
    "# Prepare a nodata mask\n",
    "nodata = data.red == data.red.odc.nodata\n",
    "\n",
    "# Combine the cloud mask and the nodata mask\n",
    "mask = cloud_mask | nodata\n",
    "\n",
    "# Apply the mask to the data\n",
    "masked = data.where(~mask, other=np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview the masked data\n",
    "masked_subset = masked[[\"red\", \"green\", \"blue\"]].isel(time=range(0, 4))\n",
    "masked_subset.to_array().plot.imshow(col=\"time\", col_wrap=2, size=6, **landsat_stretch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tide masking\n",
    "\n",
    "This cell first filters out scenes that are wholy in the \"extreme\" tides, or those\n",
    "outside the middle 50% of observations.\n",
    "\n",
    "Next it does pixel-based masking of extreme tides, as within scenes, there are still\n",
    "some regions affected by extreme tides."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add tide height to the data\n",
    "tides_hires, tides_lowres = pixel_tides(\n",
    "    masked, resample=True, directory=tide_data_location, model=\"FES2022\", dask_compute=True\n",
    ")\n",
    "\n",
    "# Determine tide cutoff\n",
    "tide_cutoff_min, tide_cutoff_max = tide_cutoffs(data, tides_lowres, tide_centre=0.0)\n",
    "\n",
    "tide_bool = (tides_hires >= tide_cutoff_min) & (tides_hires <= tide_cutoff_max)\n",
    "data_filtered = data.sel(time=tide_bool.sum(dim=[\"x\", \"y\"]) > 0)\n",
    "\n",
    "# Apply mask, and load in corresponding tide masked data\n",
    "data_tide_masked = data_filtered.where(tide_bool)\n",
    "\n",
    "print(data_tide_masked)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify land and water\n",
    "\n",
    "We use a water index, here it's a combination of the normalised difference wetness index, NDWI,\n",
    "and the modified version of that, MNDWI. We find the average of the two indices, which has been\n",
    "found to be more robust to issues of noisy data over ocean in Landsat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create MNDWI index\n",
    "data_tide_masked[\"mndwi\"] = (data_tide_masked.green - data_tide_masked.swir16) / (data_tide_masked.green + data_tide_masked.swir16)\n",
    "data_tide_masked[\"ndwi\"] = (data_tide_masked.green - data_tide_masked.nir08) / (data_tide_masked.green + data_tide_masked.nir08)\n",
    "data_tide_masked[\"combined\"] = (data_tide_masked.mndwi + data_tide_masked.ndwi) / 2\n",
    "\n",
    "# Group by year and calculate the median\n",
    "combined_by_year = data_tide_masked.combined.groupby(\"time.year\").median().to_dataset(name=\"combined\").compute()\n",
    "combined_by_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_by_year.combined.plot.imshow(col=\"year\", col_wrap=2, size=6, cmap=\"RdBu\", robust=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract contours\n",
    "\n",
    "Next we extract contour lines from the underlying land/water raster data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contour_gdf = extract_contours(combined_by_year)\n",
    "\n",
    "contour_gdf.reset_index().explore(\n",
    "    column=\"year\",\n",
    "    cmap=\"magma\",\n",
    "    style_kwds={\"weight\": 3},\n",
    "    tiles=basemaps.Esri.WorldImagery\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract points\n",
    "\n",
    "And from the contours, we extract points, and annotate them with change over time, so that\n",
    "we can document how much the coastline has eroded or accreted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract points at every 30 metres along the most recent shoreline\n",
    "points_gdf = points_on_line(contour_gdf, index=2023, distance=30)\n",
    "\n",
    "# Calculate annual movements based on the points from above\n",
    "points_gdf = annual_movements(\n",
    "    points_gdf, contours_gdf=contour_gdf, yearly_ds=combined_by_year, baseline_year=2023, water_index=\"combined\"\n",
    ")\n",
    "\n",
    "# And regression lines\n",
    "points_gdf = calculate_regressions(points_gdf=points_gdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisation\n",
    "\n",
    "Finally, visualise the results together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add human-friendly label for plotting\n",
    "points_gdf[\"Coastal change\"] = points_gdf.apply(\n",
    "    lambda x: f'<h4>This coastline has {\"<b>retreated</b>\" if x.rate_time < 0 else \"<b>grown</b>\"} '\n",
    "    f\"by</br><b>{x.rate_time:.2f} m (±{x.se_time:.1f}) per year</b> since \"\n",
    "    f\"<b>{contour_gdf.index[0]}</b></h4>\",\n",
    "    axis=1,\n",
    ")\n",
    "points_gdf.loc[points_gdf.sig_time > 0.05, \"Coastal change\"] = f\"<h4>No significant trend of retreat or growth)</h4>\"\n",
    "\n",
    "m = contour_gdf.reset_index().explore(\n",
    "    column=\"year\",\n",
    "    cmap=\"inferno\",\n",
    "    tooltip=False,\n",
    "    style_kwds={\"opacity\": 0.5},\n",
    "    categorical=True,\n",
    "    tiles=\"https://server.arcgisonline.com/ArcGIS/rest/services/World_Imagery/MapServer/tile/{z}/{y}/{x}\",\n",
    "    attr=\"ESRI WorldImagery\",\n",
    ")\n",
    "\n",
    "points_gdf.explore(\n",
    "    m=m,\n",
    "    column=\"rate_time\",\n",
    "    cmap=\"RdBu\",\n",
    "    markersize=5,\n",
    "    tooltip=\"Coastal change\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
